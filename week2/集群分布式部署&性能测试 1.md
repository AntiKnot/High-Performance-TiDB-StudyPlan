0 使用AliyunECS准备服务节点
成本预算
|配置|cost/h|...|
|-|-|-|
|16 VCore 64GB * 1|￥ 12.73 /时|tidb 3|
|4 VCore 8GB * 1|￥ 0.896 /时|PD 3|
|16 VCore 64GB 2TB (nvme ssd) * 1|￥ 12.73 /时|tikv 3|
|4 VCore 8GB * 1 500GB (ssd)|￥ 0.896 /时|Monitoring Grafana |


1.1 使用tiup构建tidb拓扑结构
先开了一个`16C 64GB`的node，部署了使用`tmp.yaml`尝试了一下。在`+ Copy files`的地方出现了大量的Error，另外是不知道重复使用创建命令会发生什么事情。
```yml
#tmp.yaml
global:
  user: "tidb"
  ssh_port: 22
  deploy_dir: "/tidb-deploy"
  data_dir: "/tidb-data"

server_configs:
  pd:
    replication.enable-placement-rules: true

pd_servers:
  - host: 47.94.44.25

tidb_servers:
  - host: 47.94.44.25

tikv_servers:
  - host: 47.94.44.25

tiflash_servers:
  - host: 47.94.44.25
    data_dir: /tidb-data/tiflash-9000
    deploy_dir: /tidb-deploy/tiflash-9000

monitoring_servers:
  - host: 47.94.44.25

grafana_servers:
  - host: 47.94.44.25

alertmanager_servers:
  - host: 47.94.44.25
```

```
$ tiup cluster deploy tidb-test v4.0.0 ./tmp.yaml --user root  -p
Starting component `cluster`: /Users/conor/.tiup/components/cluster/v1.0.9/tiup-cluster deploy tidb-test v4.0.0 ./tmp.yaml --user root -p
Please confirm your topology:
tidb Cluster: tidb-test
tidb Version: v4.0.0
Type          Host         Ports                            OS/Arch       Directories
----          ----         -----                            -------       -----------
pd            47.94.44.25  2379/2380                        linux/x86_64  /tidb-deploy/pd-2379,/tidb-data/pd-2379
tikv          47.94.44.25  20160/20180                      linux/x86_64  /tidb-deploy/tikv-20160,/tidb-data/tikv-20160
tidb          47.94.44.25  4000/10080                       linux/x86_64  /tidb-deploy/tidb-4000
tiflash       47.94.44.25  9000/8123/3930/20170/20292/8234  linux/x86_64  /tidb-deploy/tiflash-9000,/tidb-data/tiflash-9000
prometheus    47.94.44.25  9090                             linux/x86_64  /tidb-deploy/prometheus-9090,/tidb-data/prometheus-9090
grafana       47.94.44.25  3000                             linux/x86_64  /tidb-deploy/grafana-3000
alertmanager  47.94.44.25  9093/9094                        linux/x86_64  /tidb-deploy/alertmanager-9093,/tidb-data/alertmanager-9093
Attention:
    1. If the topology is not what you expected, check your yaml file.
    2. Please confirm there is no port/directory conflicts in same host.
Do you want to continue? [y/N]:  y
Input SSH password:
+ Generate SSH keys ... Done
+ Download TiDB components
  - Download pd:v4.0.0 (linux/amd64) ... Done
  - Download tikv:v4.0.0 (linux/amd64) ... Done
  - Download tidb:v4.0.0 (linux/amd64) ... Done
  - Download tiflash:v4.0.0 (linux/amd64) ... Done
  - Download prometheus:v4.0.0 (linux/amd64) ... Done
  - Download grafana:v4.0.0 (linux/amd64) ... Done
  - Download alertmanager:v0.17.0 (linux/amd64) ... Done
  - Download node_exporter:v0.17.0 (linux/amd64) ... Done
  - Download blackbox_exporter:v0.12.0 (linux/amd64) ... Done
+ Initialize target host environments
  - Prepare 47.94.44.25:22 ... Done
+ Copy files
  - Copy pd -> 47.94.44.25 ... Error
  - Copy tikv -> 47.94.44.25 ... Error
  - Copy tidb -> 47.94.44.25 ... Error
  - Copy tiflash -> 47.94.44.25 ... Done
  - Copy prometheus -> 47.94.44.25 ... Done
  - Copy grafana -> 47.94.44.25 ... Done
  - Copy alertmanager -> 47.94.44.25 ... Done
  - Copy node_exporter -> 47.94.44.25 ... Done
  - Copy blackbox_exporter -> 47.94.44.25 ... Done

Error: init config failed: 47.94.44.25:2379: open /Users/conor/.tiup/storage/cluster/clusters/tidb-test/config-cache/run_pd_47.94.44.25_2379.sh: too many open files

Verbose debug logs has been written to /Users/conor/Code/high-performance-tidb-study-plan/week2/logs/tiup-cluster-debug-2020-08-20-00-35-34.log.
Error: run `/Users/conor/.tiup/components/cluster/v1.0.9/tiup-cluster` (wd:/Users/conor/.tiup/data/S883UjQ) failed: exit status 1
```

我以为是ulimit open files 的问题
```
[root@iZ2zeg0szzi6qtlx05p6o0Z ~]# ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 256975
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 65535
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 256975
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
```

那么try again，可能是第二次需要预先准备的工作少了一些，openfiles没有达到上限。
```
tiup cluster deploy tidb-test v4.0.0 ./tmp.yaml --user root  -p
Starting component `cluster`: /Users/conor/.tiup/components/cluster/v1.0.9/tiup-cluster deploy tidb-test v4.0.0 ./tmp.yaml --user root -p
Please confirm your topology:
tidb Cluster: tidb-test
tidb Version: v4.0.0
Type          Host         Ports                            OS/Arch       Directories
----          ----         -----                            -------       -----------
pd            47.94.44.25  2379/2380                        linux/x86_64  /tidb-deploy/pd-2379,/tidb-data/pd-2379
tikv          47.94.44.25  20160/20180                      linux/x86_64  /tidb-deploy/tikv-20160,/tidb-data/tikv-20160
tidb          47.94.44.25  4000/10080                       linux/x86_64  /tidb-deploy/tidb-4000
tiflash       47.94.44.25  9000/8123/3930/20170/20292/8234  linux/x86_64  /tidb-deploy/tiflash-9000,/tidb-data/tiflash-9000
prometheus    47.94.44.25  9090                             linux/x86_64  /tidb-deploy/prometheus-9090,/tidb-data/prometheus-9090
grafana       47.94.44.25  3000                             linux/x86_64  /tidb-deploy/grafana-3000
alertmanager  47.94.44.25  9093/9094                        linux/x86_64  /tidb-deploy/alertmanager-9093,/tidb-data/alertmanager-9093
Attention:
    1. If the topology is not what you expected, check your yaml file.
    2. Please confirm there is no port/directory conflicts in same host.
Do you want to continue? [y/N]:  y
Input SSH password:
+ Generate SSH keys ... Done
+ Download TiDB components
  - Download pd:v4.0.0 (linux/amd64) ... Done
  - Download tikv:v4.0.0 (linux/amd64) ... Done
  - Download tidb:v4.0.0 (linux/amd64) ... Done
  - Download tiflash:v4.0.0 (linux/amd64) ... Done
  - Download prometheus:v4.0.0 (linux/amd64) ... Done
  - Download grafana:v4.0.0 (linux/amd64) ... Done
  - Download alertmanager:v0.17.0 (linux/amd64) ... Done
  - Download node_exporter:v0.17.0 (linux/amd64) ... Done
  - Download blackbox_exporter:v0.12.0 (linux/amd64) ... Done
+ Initialize target host environments
  - Prepare 47.94.44.25:22 ... Done
+ Copy files
  - Copy pd -> 47.94.44.25 ... Done
  - Copy tikv -> 47.94.44.25 ... Done
  - Copy tidb -> 47.94.44.25 ... Done
  - Copy tiflash -> 47.94.44.25 ... Done
  - Copy prometheus -> 47.94.44.25 ... Done
  - Copy grafana -> 47.94.44.25 ... Done
  - Copy alertmanager -> 47.94.44.25 ... Done
  - Copy node_exporter -> 47.94.44.25 ... Done
  - Copy blackbox_exporter -> 47.94.44.25 ... Done
+ Check status
Deployed cluster `tidb-test` successfully, you can start the cluster via `tiup cluster start tidb-test`
```
查看一下可用集群
```
tiup cluster list

Starting component `cluster`: /Users/xxx/.tiup/components/cluster/v1.0.9/tiup-cluster list
Name       User  Version  Path                                                   PrivateKey
----       ----  -------  ----                                                   ----------
tidb-test  tidb  v4.0.0   /Users/xxx/.tiup/storage/cluster/clusters/tidb-test  /Users/xxx/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa
```
检查指定集群,欧吼，涉及系统运维和检测的服务都是inactive状态，而tidb集群和核心组建处于down的状态。合情合理。
```
$ tiup cluster display tidb-test

Starting component `cluster`: /Users/conor/.tiup/components/cluster/v1.0.9/tiup-cluster display tidb-test
tidb Cluster: tidb-test
tidb Version: v4.0.0
ID                 Role          Host         Ports                            OS/Arch       Status    Data Dir                      Deploy Dir
--                 ----          ----         -----                            -------       ------    --------                      ----------
47.94.44.25:9093   alertmanager  47.94.44.25  9093/9094                        linux/x86_64  inactive  /tidb-data/alertmanager-9093  /tidb-deploy/alertmanager-9093
47.94.44.25:3000   grafana       47.94.44.25  3000                             linux/x86_64  inactive  -                             /tidb-deploy/grafana-3000
47.94.44.25:2379   pd            47.94.44.25  2379/2380                        linux/x86_64  Down      /tidb-data/pd-2379            /tidb-deploy/pd-2379
47.94.44.25:9090   prometheus    47.94.44.25  9090                             linux/x86_64  inactive  /tidb-data/prometheus-9090    /tidb-deploy/prometheus-9090
47.94.44.25:4000   tidb          47.94.44.25  4000/10080                       linux/x86_64  Down      -                             /tidb-deploy/tidb-4000
47.94.44.25:9000   tiflash       47.94.44.25  9000/8123/3930/20170/20292/8234  linux/x86_64  Down      /tidb-data/tiflash-9000       /tidb-deploy/tiflash-9000
47.94.44.25:20160  tikv          47.94.44.25  20160/20180                      linux/x86_64  Down      /tidb-data/tikv-20160         /tidb-deploy/tikv-20160
```
尝试启动  fire! 第一次点火失败
```
tiup cluster start tidb-test

Starting component `cluster`: /Users/conor/.tiup/components/cluster/v1.0.9/tiup-cluster start tidb-test
Starting cluster tidb-test...
+ [ Serial ] - SSHKeySet: privateKey=/Users/conor/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa, publicKey=/Users/conor/.tiup/storage/cluster/clusters/tidb-test/ssh/id_rsa.pub
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [Parallel] - UserSSH: user=tidb, host=47.94.44.25
+ [ Serial ] - StartCluster
Starting component pd
	Starting instance pd 47.94.44.25:2379
retry error: operation timed out after 2m0s
	pd 47.94.44.25:2379 failed to start: timed out waiting for port 2379 to be started after 2m0s, please check the log of the instance

Error: failed to start pd: 	pd 47.94.44.25:2379 failed to start: timed out waiting for port 2379 to be started after 2m0s, please check the log of the instance: timed out waiting for port 2379 to be started after 2m0s

Verbose debug logs has been written to /Users/conor/Code/high-performance-tidb-study-plan/week2/logs/tiup-cluster-debug-2020-08-20-00-50-54.log.
Error: run `/Users/conor/.tiup/components/cluster/v1.0.9/tiup-cluster` (wd:/Users/conor/.tiup/data/S887oc1) failed: exit status 1
```

也许官方的4.0.0在这种单机上部署一堆的方式，辉引起错误。使用nightly试试。
释放，明天继续。计划开启N*ECS拓扑部署